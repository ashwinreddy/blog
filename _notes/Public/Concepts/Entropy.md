---
title: "Entropy"
feed: hide
---

Entropy is a measure of disorder. It is a term that is used both in information theory and in thermodynamics, but the mathematical form is similar.

## Shannon entropy

It is the expected Shannon [[Information]] of a random variable.

$$
H(X) = \mathbb{E}_X\left[I(x)\right]
$$

## Thermodynamics

---